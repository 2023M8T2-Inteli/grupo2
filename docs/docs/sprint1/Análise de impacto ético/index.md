# Análise de impacto ético

Ao passo que a automação, robótica e inteligência artificial ficam mais presentes em ambientes diversos, é importante levantar discussões quanto à privacidade e proteção dos dados que essas aplicações gerenciam. Este tópico explora a interseção entre tecnologia e diversos pontos de preocupação ética no cenário de um artefato robótico com capacidade de navegação autônoma, capaz de receber ordens de busca de itens em um almoxarifado. No contexto desse projeto, a preocupação central é a segurança dos dados utilizados pelo robô, que podem variar desde informações sensíveis sobre ativos valiosos até dados relacionados à saúde e configuração de produção em uma fábrica. Para mitigar esses riscos, a implementação de estratégias robustas de criptografia e tokenização são discutidas, no contexto de armazenamento em nuvem. Além disso, questões de equidade e justiça, destacando desafios potenciais para usuários com diferentes habilidades linguísticas, deficiências físicas ou idades avançadas também foi discutido. A transparência e o consentimento informado são considerados imperativos, assegurando que os usuários compreendam plenamente o propósito e o funcionamento da tecnologia. Por fim, a responsabilidade social associada à automação, destacando a importância de realocação e treinamento adequados para os trabalhadores afetados foi discutida. Este tópico busca contextualizar a interseção complexa entre tecnologia emergente e considerações éticas, destacando a necessidade de abordagens equilibradas e conscientes por parte das entidades que as desenvolvem e as que a utilizam.

### EQUIDADE E JUSTIÇA

Acredita-se que a solução apresentada ao parceiro deva contemplar as múltiplas características que a persona elaborada pelo grupo possa apresentar. Dessa forma, é imperativo o mapeamento de possíveis disparidades impulsionadas pela utilização do sistema proposto. As possibilidades identificadas encontram-se dispostas abaixo.

(1) Uma das partes do sistema caracteriza-se por um software através do qual será possível realizar a solicitação de um item do almoxarifado. A interface de interação com o usuário será um chatbot de caráter speech-to-text. Dessa forma, pode haver injustiça com o funcionário que apresenta dificuldades de fala, uma vez que o modelo de processamento de linguagem falha ao interpretar o comando anunciado. A fim de mitigar a ocorrência da situação destacada, o caráter speech-to-text do chatbot deverá ser opcional, e demais possibilidades de interação com a ferramenta devem ser apresentadas. Dessa forma, se o usuário preferir digitar uma descrição correspondente à sua solicitação, esta deverá ser igualmente interpretada pela ferramenta de inteligência artificial. A solicitação deve ser processada de forma acessível, independentemente do meio escolhido pelo usuário para realizá-la.
É importante destacar, também, que a mesma situação pode ocorrer em dispositivos que exijam que o usuário emita comandos por voz. Nesse caso, é fundamental refletir sobre a acessibilidade do sistema para que pessoas com alguma deficiência, por exemplo, sejam contempladas pela solução assim como todos os outros usuários.

(2) Assim como no exemplo anterior, identificou-se a possibilidade de inacessibilidade de uso do chatbot para pessoas estrangeiras. Considerando a característica speech-to-text, um funcionário que não se comunica fluentemente em língua portuguesa ou que carrega um sotaque acentuado pode enfrentar dificuldades significativas ao ter seu discurso interpretado pela inteligência artificial. Para mitigar o risco, recomenda-se adotar outros idiomas para interação com o chatbot, bem como fornecer ao usuário alternativas para realizar sua solicitação, a exemplo de inserção de texto para envio do comando. Empresas que adotam soluções semelhantes devem mapear funcionários que não se comuniquem no idioma do produto ou que não falem a língua fluentemente. Dessa forma, os usuários mapeados poderiam participar de testes com o objetivo de aprimorar a ferramenta, de modo que ela se torne acessível a esse público.

(3) Ao interagir com o chatbot no processo de solicitação de itens do almoxarifado, há a possibilidade de que a resposta fornecida para o usuário tenha caráter ofensivo ou discriminatório, frente à possibilidade de que os dados utilizados na solução possam criar vieses no processo de aprendizado de máquina. A fim de evitar essa situação, a solução proposta para o parceiro não irá solicitar dados sensíveis do usuário. Dessa forma, espera-se que o modelo não forneça respostas que se dirijam, diretamente, ao usuário e às suas características. A interação entre o usuário e a inteligência artificial, desse modo, deverá ocorrer de forma amigável e simples. É necessário atentar-se às soluções que, anteriormente ao atendimento do usuário, solicitem dados pessoais capazes de influenciar a inteligência artificial. Recomenda-se, nesse caso, que seja opcional a coleta de dados por meio do sistema. Se a coleta de dados for necessária para o funcionamento da solução, será necessário treinar o modelo de forma a evitar vieses e respostas discriminatórias.

(4) Ao utilizar o software desenvolvido para realizar uma requisição para o almoxarifado, grupos de pessoas com deficiência podem ter sua experiência de uso limitada, uma vez que haja incompatibilidade entre a limitação apresentada pelo usuário e os requisitos de uso implicados pela aplicação. Algumas estratégias podem ser adotadas para evitar essa limitação. No caso de pessoas com deficiência visual parcial, a interface deve possibilitar a personalização dos elementos da página a fim de tornar sua visualização mais acessível. Nesse caso, pode haver a opção de aumentar a fonte dos textos, modificar o brilho da tela, entre outros recursos visuais que facilitem a interação. No caso de pessoas com deficiência visual completa, será necessário que haja um leitor de tela ou que a requisição possa ser feita com o apoio do profissional responsável pelo almoxarifado, por exemplo.
Soluções que envolvam interação com um software, de modo geral, estão igualmente suscetíveis ao problema evidenciado. É fundamental que a solução também possa ser utilizada por esse público, de forma que o objetivo do uso seja devidamente alcançado.

(5) Caso o técnico de manutenção que irá realizar a solicitação ao almoxarifado seja uma pessoa idosa, ele pode se deparar com situações de injustiça ao apresentar dificuldades para manipular a tecnologia. Dessa forma, pode ser impedido de realizar uma requisição devido a limitações técnicas impostas pela complexidade do software. Para impedir a ocorrência de situações semelhantes, o técnico que não possuir nenhuma familiaridade com a tecnologia, devido a sua faixa etária, deve ser convidado a uma jornada de treinamento para aprender a utilizar o software. Cabe à empresa parceira, ante a implementação do sistema em seu almoxarifado, capacitar as pessoas que irão utilizar a solução, uma vez que a interação com tecnologias pode não estar presente no cotidiano dos usuários, dificultando significativamente o uso. Ambientes industriais que adotam soluções semelhantes devem realizar o mapeamento da jornada do usuário que se encaixa na característica mencionada. Dessa forma, será possível solicitar o feedback dos funcionários contemplados e aprimorar a solução a fim de tornar sua usabilidade mais fluida.

(6) Caso o LCD acoplado ao robô constitua uma interface de interação com o hardware, o assistente de almoxarifado terá que abaixar até o robô para visualizar a tela. Nesse contexto, pode haver a exclusão de pessoas com deficiência locomotora e/ou de pessoas idosas que precisem comprometer a ergonomia da qual dispõem no ambiente de trabalho. Para evitar o problema mencionado, é possível desenvolver um suporte de altura regulável para a tela, a fim de que não seja necessário abaixar para alcançar a altura do robô.
Destaca-se, também, que essa situação pode ocorrer em quaisquer outras soluções nas quais uma interface esteja acoplada ao robô autônomo. A presença de um suporte capaz de regular a altura da tela, nesse caso, é imprescindível para que a solução seja acessível aos funcionários e colaboradores que possuam limitações físicas.

Ao mapear possíveis impedimentos para a garantia da equidade de uso do sistema, torna-se possível trabalhar nos pontos de fragilidade da solução e traçar estratégias capazes de mitigar os riscos considerados. Desse modo, acredita-se que, ao desenvolver melhorias relativas aos pontos mencionados, será possível entregar um produto mínimo viável (MVP) de forma a garantir que sua usabilidade seja equitativa e justa.

### TRANSPARÊNCIA E CONSENTIMENTO INFORMADO

Uma vez que a solução é implementada no ambiente de trabalho de seus usuários, deve haver transparência a respeito do produto. Entende-se que a inadequação a esse critério pode levar o usuário à falta de confiança na tecnologia, de modo que a adaptação ao novo recurso não seja bem-sucedida. É imperativo que, no período de implementação da solução, todos os funcionários contemplados pelo robô de serviço estejam cientes de sua função no contexto em que está inserido. Toda a documentação do produto deverá ser disponibilizada, em linguagem acessível e em plataformas de fácil acesso, para os colaboradores do almoxarifado. Além disso, a equipe responsável pela implementação da solução deve dedicar determinado período de tempo a esclarecer possíveis dúvidas levantadas pelos futuros usuários, a fim de diminuir possíveis desconfianças relacionadas ao uso do robô.
No que se refere à interação entre usuário e chatbot, destaca-se que a ferramenta de inteligência artificial — componente imprescindível para o funcionamento do sistema — não irá coletar dados sensíveis a respeito dos funcionários. A única informação necessária será o número de identificação do funcionário, para que seja possível registrar a solicitação que se deseja fazer. Os demais dados utilizados pela ferramenta se referem aos itens presentes no almoxarifado, os quais serão mantidos e preservados pela solução de forma transparente e segura. Todas as diretrizes estabelecidas pela Lei Geral de Proteção de Dados (LGPD) serão seguidas.
